package executor

import (
	"fmt"

	"github.com/agnath18K/lumo/pkg/ai"
	"github.com/agnath18K/lumo/pkg/nlp"
)

// handleModelList handles the model list command
func (e *Executor) handleModelList(cmd *nlp.Command) (*Result, error) {
	var output string
	switch e.config.AIProvider {
	case "gemini":
		output = `
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¦ Available Gemini Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®

  â€¢ gemini-2.0-flash-lite  (Fast, efficient for most queries)
  â€¢ gemini-2.0-flash       (Balanced performance and quality)
  â€¢ gemini-2.0-pro         (High quality, more capabilities)

  Current model: ` + e.config.GeminiModel + `

â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
`
	case "ollama":
		// Try to get the list of models from Ollama
		ollamaClient := ai.NewOllamaClient(e.config.OllamaURL, e.config.OllamaModel)
		models, err := ollamaClient.ListModels()

		if err != nil {
			return &Result{
				Output:     fmt.Sprintf("Error getting models from Ollama: %v", err),
				IsError:    true,
				CommandRun: cmd.RawInput,
			}, nil
		}

		// Build the model list
		modelList := ""
		for _, model := range models {
			modelList += "  â€¢ " + model + "\n"
		}

		if modelList == "" {
			modelList = "  No models found. Use 'ollama pull <model>' to download models.\n"
		}

		output = fmt.Sprintf(`
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¦ Available Ollama Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®

%s
  Current model: %s

  Note: To download more models, use 'ollama pull <model>'
  Example: ollama pull llama3

â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
`, modelList, e.config.OllamaModel)

	default: // OpenAI
		output = `
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¦ Available OpenAI Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®

  â€¢ gpt-3.5-turbo          (Fast, cost-effective)
  â€¢ gpt-4o                 (Advanced capabilities, slower)
  â€¢ gpt-4o-mini            (Balanced performance and quality)

  Current model: ` + e.config.OpenAIModel + `

â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
`
	}

	return &Result{
		Output:     output,
		IsError:    false,
		CommandRun: cmd.RawInput,
	}, nil
}
